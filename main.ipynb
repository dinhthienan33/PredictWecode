{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from ck-public.csv:\n",
      "                                 student_id   CK\n",
      "0  00b6dd4fc7eb817e03708c532016ef30ce564a61  5.5\n",
      "1  00bef8afee8f3c595d535c9c03c490cac1a4f021  6.5\n",
      "2  01122b3ef7e59b84189e65985305f575d6bdf83c  4.5\n",
      "3  013de369c439ab0ead8aa7da64423aa395a8be39  5.0\n",
      "4  014c59c6433fd764a0b08de6ffeb757eaf60aa73  4.0 \n",
      "\n",
      "Data from qt-public.csv:\n",
      "                                 student_id diemqt\n",
      "0  00b6dd4fc7eb817e03708c532016ef30ce564a61    7.5\n",
      "1  00bef8afee8f3c595d535c9c03c490cac1a4f021      7\n",
      "2  01122b3ef7e59b84189e65985305f575d6bdf83c      9\n",
      "3  013de369c439ab0ead8aa7da64423aa395a8be39     10\n",
      "4  014c59c6433fd764a0b08de6ffeb757eaf60aa73      9 \n",
      "\n",
      "Data from tbtl-public.csv:\n",
      "                                 student_id  TBTL\n",
      "0  00b6dd4fc7eb817e03708c532016ef30ce564a61  7.24\n",
      "1  00bef8afee8f3c595d535c9c03c490cac1a4f021  8.11\n",
      "2  01122b3ef7e59b84189e65985305f575d6bdf83c  7.30\n",
      "3  0134f9f410c65ad0e8c2254a7e9288670e02a183  8.63\n",
      "4  013de369c439ab0ead8aa7da64423aa395a8be39  8.20 \n",
      "\n",
      "Data from th-public.csv:\n",
      "                                 student_id   TH\n",
      "0  00b6dd4fc7eb817e03708c532016ef30ce564a61    5\n",
      "1  00bef8afee8f3c595d535c9c03c490cac1a4f021  8.5\n",
      "2  01122b3ef7e59b84189e65985305f575d6bdf83c    7\n",
      "3  013de369c439ab0ead8aa7da64423aa395a8be39   10\n",
      "4  014c59c6433fd764a0b08de6ffeb757eaf60aa73    6 \n",
      "\n",
      "Annonimized data:\n",
      "                              assignment_id  \\\n",
      "0  90ce27571176d87961b565d5ef4b3de33ede04ac   \n",
      "1  90ce27571176d87961b565d5ef4b3de33ede04ac   \n",
      "2  90ce27571176d87961b565d5ef4b3de33ede04ac   \n",
      "3  90ce27571176d87961b565d5ef4b3de33ede04ac   \n",
      "4  90ce27571176d87961b565d5ef4b3de33ede04ac   \n",
      "\n",
      "                                 problem_id  \\\n",
      "0  789454427dd4097a14749e3dde63346b7a8d3811   \n",
      "1  789454427dd4097a14749e3dde63346b7a8d3811   \n",
      "2  789454427dd4097a14749e3dde63346b7a8d3811   \n",
      "3  bf96fbdc5f499538c3e2bfbec5779c8a14b0a9ff   \n",
      "4  7a6e5ca470ff47c3b5048f240c4738de71010c78   \n",
      "\n",
      "                                 student_id  is_final status  pre_score  \\\n",
      "0  ed9eaeb6a707f50154024b24d7efcb874a9795dd         0  SCORE          0   \n",
      "1  ed9eaeb6a707f50154024b24d7efcb874a9795dd         0  SCORE          0   \n",
      "2  ed9eaeb6a707f50154024b24d7efcb874a9795dd         1  SCORE      10000   \n",
      "3  ed9eaeb6a707f50154024b24d7efcb874a9795dd         1  SCORE      10000   \n",
      "4  ed9eaeb6a707f50154024b24d7efcb874a9795dd         1  SCORE      10000   \n",
      "\n",
      "   coefficient language_id      created_at      updated_at  \\\n",
      "0          100      it0012  10-09 08:02:04  10-09 08:06:58   \n",
      "1          100      it0012  10-09 08:04:41  10-09 08:04:51   \n",
      "2          100      it0012  10-09 08:06:49  10-09 08:06:58   \n",
      "3          100      it0012  10-09 08:47:52  10-09 08:48:01   \n",
      "4          100      it0012  10-09 09:19:35  10-09 09:19:45   \n",
      "\n",
      "                                           judgement  \n",
      "0  {\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...  \n",
      "1  {\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...  \n",
      "2  {\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...  \n",
      "3  {\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...  \n",
      "4  {\"times\":[0,0,0,0,0,0,0,0,0,0],\"mems\":[0,0,0,0...   \n",
      "\n",
      "Student data:\n",
      "                                       hash\n",
      "0  ed9eaeb6a707f50154024b24d7efcb874a9795dd\n",
      "1  ba12c0a2cb367af0467e479c03507c71a805d291\n",
      "2  0bd2037bf68a97753e5e67ab55dac026a649f279\n",
      "3  b7298b0fe50443a623af9b56792b330c2d052845\n",
      "4  c60be70309789b39355dc612f36e37090ccad5dc \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "extracted_train_folder = 'extracted_train_data_files'\n",
    "extracted_annonimized_folder = 'extracted_annonimized_files'\n",
    "extracted_train_files = os.listdir(extracted_train_folder)\n",
    "extracted_annonimized_files = os.listdir(extracted_annonimized_folder)\n",
    "# Load the training data files\n",
    "train_file_paths = [os.path.join(extracted_train_folder, file) for file in extracted_train_files]\n",
    "train_dfs = {os.path.basename(path): pd.read_csv(path) for path in train_file_paths}\n",
    "\n",
    "# Load the annonimized data\n",
    "annonimized_df = pd.read_csv('extracted_annonimized_files/annonimized.csv')\n",
    "\n",
    "# Load the student data\n",
    "student_data_path = 'student.csv'\n",
    "student_df = pd.read_csv(student_data_path)\n",
    "\n",
    "# Display the first few rows of each DataFrame\n",
    "for file_name, df in train_dfs.items():\n",
    "    print(f\"Data from {file_name}:\")\n",
    "    print(df.head(), \"\\n\")\n",
    "\n",
    "print(\"Annonimized data:\")\n",
    "print(annonimized_df.head(), \"\\n\")\n",
    "\n",
    "print(\"Student data:\")\n",
    "print(student_df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\APTS\\AppData\\Local\\Temp\\ipykernel_17288\\562458736.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  annonimized_df['created_at'] = pd.to_datetime(annonimized_df['created_at']).dt.date\n"
     ]
    },
    {
     "ename": "OutOfBoundsDatetime",
     "evalue": "Out of bounds nanosecond timestamp: 10-09 08:02:04, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mconversion.pyx:326\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion._TSObject.ensure_reso\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mnp_datetime.pyx:683\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.np_datetime.convert_reso\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: result would overflow",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[225], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert submission and evaluation dates to datetime\u001b[39;00m\n\u001b[0;32m      2\u001b[0m annonimized_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextracted_annonimized_files/annonimized.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m annonimized_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannonimized_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreated_at\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n\u001b[0;32m      5\u001b[0m annonimized_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# annonimized_df['created_at'] = pd.to_datetime(annonimized_df['created_at'], errors='coerce')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# annonimized_df['updated_at'] = pd.to_datetime(annonimized_df['updated_at'], errors='coerce')\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# annonimized_df['submission_delay'] = (annonimized_df['updated_at'] - annonimized_df['created_at']).dt.total_seconds()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\APTS\\anaconda3\\envs\\myenv2\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Users\\APTS\\anaconda3\\envs\\myenv2\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\APTS\\anaconda3\\envs\\myenv2\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[1;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabbrev_to_npy_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_unit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2405\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[1;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:596\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:571\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:332\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion._TSObject.ensure_reso\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 10-09 08:02:04, at position 0"
     ]
    }
   ],
   "source": [
    "# Convert submission and evaluation dates to datetime\n",
    "annonimized_df = pd.read_csv('extracted_annonimized_files/annonimized.csv')\n",
    "\n",
    "# annonimized_df['created_at'] = '2023-' + str(annonimized_df['created_at'])\n",
    "# annonimized_df['updated_at'] = '2023-' + str(annonimized_df['updated_at']) \n",
    "# annonimized_df['created_at'] = pd.to_datetime(annonimized_df['created_at'], errors='ignore')\n",
    "# annonimized_df['updated_at'] = pd.to_datetime(annonimized_df['updated_at'], errors='ignore')\n",
    "\n",
    "# annonimized_df['submission_delay'] = (annonimized_df['updated_at'] - annonimized_df['created_at']).dt.total_seconds()\n",
    "annonimized_df=annonimized_df.drop(columns=['problem_id','language_id'],axis=1)\n",
    "# Aggregate features for each student\n",
    "student_agg = annonimized_df.groupby('student_id').agg(\n",
    "    total_submissions=('assignment_id', 'count'),\n",
    "    avg_testcase_passed=('pre_score', 'mean'),\n",
    "    max_testcase_passed=('pre_score', 'max'),\n",
    "    min_testcase_passed=('pre_score', 'min'),\n",
    "    scored_submissions=('is_final', lambda x: (x == 1).sum()),\n",
    "    late_submissions=('coefficient', lambda x: (x < 100).sum())\n",
    ").reset_index()\n",
    "student_agg.to_csv('all_student3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('all_student3.csv')\n",
    "# Assuming `df` is your DataFrame containing the original features\n",
    "df['success_rate'] = df['avg_testcase_passed'] / df['total_submissions']\n",
    "df['scored_to_total_ratio'] = df['scored_submissions'] / df['total_submissions']\n",
    "df['testcase_range'] = df['max_testcase_passed'] - df['min_testcase_passed']\n",
    "df['total_testcases_passed'] = df[['avg_testcase_passed', 'max_testcase_passed', 'min_testcase_passed']].sum(axis=1)\n",
    "df.to_csv('all_student2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_student=pd.read_csv('all_student2.csv')\n",
    "student_train=pd.read_csv('train_student.csv')\n",
    "student_train=all_student.merge(student_train,on='student_id',how='right')\n",
    "student_train.to_csv('student_train_with_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_student=pd.read_csv('all_student2.csv')\n",
    "student_test=pd.read_csv('student_test.csv')\n",
    "student_train=all_student.merge(student_test,on='student_id',how='right')\n",
    "student_train.to_csv('student_test_with_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Corrected: Read the CSV file into a DataFrame\n",
    "all_student_train = pd.read_csv('student_train_with_features.csv')\n",
    "all_student_test = pd.read_csv('student_test_with_features.csv')\n",
    "\n",
    "# Instantiate the LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Assuming you want to encode the 'some_column' column\n",
    "# Replace 'some_column' with the actual column name you want to encode\n",
    "all_student_train['student_id'] = encoder.fit_transform(all_student_train['student_id'])\n",
    "all_student_test['student_id'] = encoder.fit_transform(all_student_test['student_id'])\n",
    "all_student_train.to_csv('student_train_with_features_final.csv',index=False)\n",
    "all_student_test.to_csv('student_test_with_features_final.csv',index=False)\n",
    "# Now 'all_student' DataFrame has a new column 'some_column_encoded' with encoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine the training data into a single DataFrame if necessary\n",
    "student_train=pd.read_csv('student_train_with_features.csv')\n",
    "ck=pd.read_csv('extracted_train_data_files\\ck-public.csv')\n",
    "student_train_score=student_train.merge(ck,on='student_id',how='inner')\n",
    "student_train_score.to_csv('student_train_with_score.csv',index=False)\n",
    "# for df in train_dfs.values():\n",
    "#     student_train=student_train.merge(df,on='student_id',how='outer')\n",
    "# student_train.to_csv('student_train_with_score.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine the training data into a single DataFrame if necessary\n",
    "student_train=pd.read_csv('student_train_with_score.csv')\n",
    "qt=pd.read_csv('extracted_train_data_files\\qt-public.csv')\n",
    "student_train_score=student_train.merge(qt,on='student_id',how='inner')\n",
    "student_train_score.to_csv('student_train_with_score.csv',index=False)\n",
    "# for df in train_dfs.values():\n",
    "#     student_train=student_train.merge(df,on='student_id',how='outer')\n",
    "# student_train.to_csv('student_train_with_score.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine the training data into a single DataFrame if necessary\n",
    "student_train=pd.read_csv('student_train_with_score.csv')\n",
    "tbtl=pd.read_csv('extracted_train_data_files/tbtl-public.csv')\n",
    "student_train_score=student_train.merge(tbtl,on='student_id',how='inner')\n",
    "student_train_score.to_csv('student_train_with_score.csv',index=False)\n",
    "# for df in train_dfs.values():\n",
    "#     student_train=student_train.merge(df,on='student_id',how='outer')\n",
    "# student_train.to_csv('student_train_with_score.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine the training data into a single DataFrame if necessary\n",
    "student_train=pd.read_csv('student_train_with_score.csv')\n",
    "th=pd.read_csv('extracted_train_data_files/th-public.csv')\n",
    "student_train_score=student_train.merge(th,on='student_id',how='inner')\n",
    "student_train_score.to_csv('student_train_with_score.csv',index=False)\n",
    "# for df in train_dfs.values():\n",
    "#     student_train=student_train.merge(df,on='student_id',how='outer')\n",
    "# student_train.to_csv('student_train_with_score.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Merge with the aggregated annonimized data\n",
    "student_train=pd.read_csv('student_train_with_score.csv')\n",
    "feature=['diemqt','TH']\n",
    "student_train[feature]=student_train[feature].replace('\\xa0', 5)\n",
    "\n",
    "# Handle missing values\n",
    "student_train.fillna(5, inplace=True)\n",
    "\n",
    "# Feature engineering (adjust based on actual features)\n",
    "# Example: Create new features or transform existing ones if necessary\n",
    "\n",
    "student_train.to_csv('training.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['total_submissions', 'avg_testcase_passed', 'max_testcase_passed', 'min_testcase_passed', 'scored_submissions', 'late_submissions','success_rate','scored_to_total_ratio','testcase_range','total_testcases_passed']\n",
    "targets = ['CK', 'diemqt', 'TBTL', 'TH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_id                761\n",
      "total_submissions         377\n",
      "avg_testcase_passed       745\n",
      "max_testcase_passed        11\n",
      "min_testcase_passed        12\n",
      "scored_submissions        130\n",
      "late_submissions           33\n",
      "success_rate              748\n",
      "scored_to_total_ratio     663\n",
      "testcase_range             17\n",
      "total_testcases_passed    746\n",
      "CK                         21\n",
      "diemqt                     20\n",
      "TBTL                      288\n",
      "TH                         20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.read_csv('training.csv')\n",
    "print(merged_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.10300496097829748\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "merged_df = pd.read_csv('training.csv')\n",
    "# Split training data\n",
    "X = merged_df[features]\n",
    "y = merged_df[targets]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=400)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred, multioutput='uniform_average')\n",
    "print(f'R^2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3.3079056421558093\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "merged_df = pd.read_csv('training.csv')\n",
    "\n",
    "X = merged_df[features]\n",
    "y = merged_df[targets]\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=452)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 student_id  total_submissions  \\\n",
      "0  ed9eaeb6a707f50154024b24d7efcb874a9795dd                139   \n",
      "1  ba12c0a2cb367af0467e479c03507c71a805d291                319   \n",
      "2  b7298b0fe50443a623af9b56792b330c2d052845                247   \n",
      "3  c60be70309789b39355dc612f36e37090ccad5dc                172   \n",
      "4  a22a58c5be8aa2c2700619e37f2b7a6e4efa7e6b                288   \n",
      "\n",
      "   avg_testcase_passed  max_testcase_passed  min_testcase_passed  \\\n",
      "0          5305.553957                10000                    0   \n",
      "1          5228.576803                10000                    0   \n",
      "2          5998.854251                10000                    0   \n",
      "3          6237.773256                10000                    0   \n",
      "4          5547.465278                10000                    0   \n",
      "\n",
      "   scored_submissions  late_submissions  success_rate  scored_to_total_ratio  \\\n",
      "0                  58                 0     38.169453               0.417266   \n",
      "1                 117                 0     16.390523               0.366771   \n",
      "2                 110                 0     24.286859               0.445344   \n",
      "3                  83                 0     36.266124               0.482558   \n",
      "4                 103                 0     19.262032               0.357639   \n",
      "\n",
      "   testcase_range  total_testcases_passed   CK  diemqt  TBTL   TH  \n",
      "0           10000            15305.553957  6.5     8.5   8.0  8.0  \n",
      "1           10000            15228.576803  5.5     9.0   8.0  8.5  \n",
      "2           10000            15998.854251  4.5     8.5   8.5  8.0  \n",
      "3           10000            16237.773256  6.5     8.5   8.5  8.0  \n",
      "4           10000            15547.465278  6.0     9.0   8.0  8.5  \n"
     ]
    }
   ],
   "source": [
    "# Predict for the student data\n",
    "student_df=pd.read_csv('student_test_with_features.csv')\n",
    "\n",
    "student_X = student_df[features]\n",
    "predictions=model.predict(student_X)\n",
    "student_predictions = np.round_(predictions*2)/2\n",
    "\n",
    "# Add predictions to the student DataFrame\n",
    "student_df[targets] = student_predictions\n",
    "# Save the predictions\n",
    "student_df[['student_id', 'TH']].to_csv('result_th.csv', index=False)\n",
    "print(student_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
